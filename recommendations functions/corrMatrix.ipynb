{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\KimYiuLui\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rake_nltk import Rake\n",
    "import numpy as np\n",
    "import re, string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize \n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "stopwords = set(stopwords.words('english'))\n",
    "extraWords= ['whence', 'here', 'show', 'were', 'why',\"'s'\",\"n't\",\"'ve\", 'n’t', 'the', 'whereupon', 'not', 'more', 'how', 'eight', 'indeed', 'i', 'only', 'via', 'nine', 're', 'themselves', 'almost', 'to', 'already', 'front', 'least', 'becomes', 'thereby', 'doing', 'her', 'together', 'be', 'often', 'then', 'quite', 'less', 'many', 'they', 'ourselves', 'take', 'its', 'yours', 'each', 'would', 'may', 'namely', 'do', 'whose', 'whether', 'side', 'both', 'what', 'between', 'toward', 'our', 'whereby', \"'m\", 'formerly', 'myself', 'had', 'really', 'call', 'keep', \"'re\", 'hereupon', 'can', 'their', 'eleven', '’m', 'even', 'around', 'twenty', 'mostly', 'did', 'at', 'an', 'seems', 'serious', 'against', \"n't\", 'except', 'has', 'five', 'he', 'last', '‘ve', 'because', 'we', 'himself', 'yet', 'something', 'somehow', '‘m', 'towards', 'his', 'six', 'anywhere', 'us', '‘d', 'thru', 'thus', 'which', 'everything', 'become', 'herein', 'one', 'in', 'although', 'sometime', 'give', 'cannot', 'besides', 'across', 'noone', 'ever', 'that', 'over', 'among', 'during', 'however', 'when', 'sometimes', 'still', 'seemed', 'get', \"'ve\", 'him', 'with', 'part', 'beyond', 'everyone', 'same', 'this', 'latterly', 'no', 'regarding', 'elsewhere', 'others', 'moreover', 'else', 'back', 'alone', 'somewhere', 'are', 'will', 'beforehand', 'ten', 'very', 'most', 'three', 'former', '’re', 'otherwise', 'several', 'also', 'whatever', 'am', 'becoming', 'beside', '’s', 'nothing', 'some', 'since', 'thence', 'anyway', 'out', 'up', 'well', 'it', 'various', 'four', 'top', '‘s', 'than', 'under', 'might', 'could', 'by', 'too', 'and', 'whom', '‘ll', 'say', 'therefore', \"'s\", 'other', 'throughout', 'became', 'your', 'put', 'per', \"'ll\", 'fifteen', 'must', 'before', 'whenever', 'anyone', 'without', 'does', 'was', 'where', 'thereafter', \"'d\", 'another', 'yourselves', 'n‘t', 'see', 'go', 'wherever', 'just', 'seeming', 'hence', 'full', 'whereafter', 'bottom', 'whole', 'own', 'empty', 'due', 'behind', 'while', 'onto', 'wherein', 'off', 'again', 'a', 'two', 'above', 'therein', 'sixty', 'those', 'whereas', 'using', 'latter', 'used', 'my', 'herself', 'hers', 'or', 'neither', 'forty', 'thereupon', 'now', 'after', 'yourself', 'whither', 'rather', 'once', 'from', 'until', 'anything', 'few', 'into', 'such', 'being', 'make', 'mine', 'please', 'along', 'hundred', 'should', 'below', 'third', 'unless', 'upon', 'perhaps', 'ours', 'but', 'never', 'whoever', 'fifty', 'any', 'all', 'nobody', 'there', 'have', 'anyhow', 'of', 'seem', 'down', 'is', 'every', '’ll', 'much', 'none', 'further', 'me', 'who', 'nevertheless', 'about', 'everywhere', 'name', 'enough', '’d', 'next', 'meanwhile', 'though', 'through', 'on', 'first', 'been', 'hereby', 'if', 'move', 'so', 'either', 'amongst', 'for', 'twelve', 'nor', 'she', 'always', 'these', 'as', '’ve', 'amount', '‘re', 'someone', 'afterwards', 'you', 'nowhere', 'itself', 'done', 'hereafter', 'within', 'made', 'ca', 'them', 'her', 'during', 'among', 'thereafter', 'only', 'hers', 'in', 'none', 'with', 'un', 'put', 'hence', 'each', 'would', 'have', 'to', 'itself', 'that', 'seeming', 'hereupon', 'someone', 'eight', 'she', 'forty', 'much', 'throughout', 'less', 'was', 'interest', 'elsewhere', 'already', 'whatever', 'or', 'seem', 'fire', 'however', 'keep', 'detail', 'both', 'yourselves', 'indeed', 'enough', 'too', 'us', 'wherein', 'himself', 'behind', 'everything', 'part', 'made', 'thereupon', 'for', 'nor', 'before', 'front', 'sincere', 'really', 'than', 'alone', 'doing', 'amongst', 'across', 'him', 'another', 'some', 'whoever', 'four', 'other', 'latterly', 'off', 'sometime', 'above', 'often', 'herein', 'am', 'whereby', 'although', 'who', 'should', 'amount', 'anyway', 'else', 'upon', 'this', 'when', 'we', 'few', 'anywhere', 'will', 'though', 'being', 'fill', 'used', 'full', 'thru', 'call', 'whereafter', 'various', 'has', 'same', 'former', 'whereas', 'what', 'had', 'mostly', 'onto', 'go', 'could', 'yourself', 'meanwhile', 'beyond', 'beside', 'ours', 'side', 'our', 'five', 'nobody', 'herself', 'is', 'ever', 'they', 'here', 'eleven', 'fifty', 'therefore', 'nothing', 'not', 'mill', 'without', 'whence', 'get', 'whither', 'then', 'no', 'own', 'many', 'anything', 'etc', 'make', 'from', 'against', 'ltd', 'next', 'afterwards', 'unless', 'while', 'thin', 'beforehand', 'by', 'amoungst', 'you', 'third', 'as', 'those', 'done', 'becoming', 'say', 'either', 'doesn', 'twenty', 'his', 'yet', 'latter', 'somehow', 'are', 'these', 'mine', 'under', 'take', 'whose', 'others', 'over', 'perhaps', 'thence', 'does', 'where', 'two', 'always', 'your', 'wherever', 'became', 'which', 'about', 'but', 'towards', 'still', 'rather', 'quite', 'whether', 'somewhere', 'might', 'do', 'bottom', 'until', 'km', 'yours', 'serious', 'find', 'please', 'hasnt', 'otherwise', 'six', 'toward', 'sometimes', 'of', 'fifteen', 'eg', 'just', 'a', 'me', 'describe', 'why', 'an', 'and', 'may', 'within', 'kg', 'con', 're', 'nevertheless', 'through', 'very', 'anyhow', 'down', 'nowhere', 'now', 'it', 'cant', 'de', 'move', 'hereby', 'how', 'found', 'whom', 'were', 'together', 'again', 'moreover', 'first', 'never', 'below', 'between', 'computer', 'ten', 'into', 'see', 'everywhere', 'there', 'neither', 'every', 'couldnt', 'up', 'several', 'the', 'i', 'becomes', 'don', 'ie', 'been', 'whereupon', 'seemed', 'most', 'noone', 'whole', 'must', 'cannot', 'per', 'my', 'thereby', 'so', 'he', 'name', 'co', 'its', 'everyone', 'if', 'become', 'thick', 'thus', 'regarding', 'didn', 'give', 'all', 'show', 'any', 'using', 'on', 'further', 'around', 'back', 'least', 'since', 'anyone', 'once', 'can', 'bill', 'hereafter', 'be', 'seems', 'their', 'myself', 'nine', 'also', 'system', 'at', 'more', 'out', 'twelve', 'therein', 'almost', 'except', 'last', 'did', 'something', 'besides', 'via', 'whenever', 'formerly', 'cry', 'one', 'hundred', 'sixty', 'after', 'well', 'them', 'namely', 'empty', 'three', 'even', 'along', 'because', 'ourselves', 'such', 'top', 'due', 'inc', 'themselves', 'ii', 'th', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i','j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', 'mr', 'us', 'dk', 'workthis', 'youve', 'ive', 'sheve', 'heve', 'weve', 'theyve', 'didnt', 'dont', 'wouldnt', 'couldnt', 'cant', 'shouldnt', 'gl','cm', '________________________________', 'wwwultimatewritercom', 'svd', 'psg', 'zfxpsg', 'editorairsoftpresscom', 'iihf', 'miif','cae']\n",
    "for word in extraWords:\n",
    "    stopwords.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import kaggle dataset and clean it\n",
    "# we want english books with the format 1,2,9 see format.csv for reference\n",
    "df = pd.read_csv(\"../dataset/dataset.csv\")\n",
    "df = df[df.lang == \"en\"]\n",
    "formats = [\"1\",\"2\",\"9\"]\n",
    "df = df[df.format.isin(formats)]\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# after filtering only return the title and description to work with\n",
    "data = df[[\"title\", \"description\"]]\n",
    "data.columns = [\"Title\", \"Description\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KimYiuLui\\Anaconda3\\envs\\minor\\lib\\site-packages\\pandas\\core\\generic.py:6245: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "# fill empty description with unknown instead of removing it\n",
    "# because in real life example a description might be added later\n",
    "data['Description'].fillna(\"unknown\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to clean the description.\n",
    "stop = text.ENGLISH_STOP_WORDS\n",
    "\n",
    "def remove_noise(text):\n",
    "    # Make lowercase\n",
    "    text = text.apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
    "    \n",
    "    # Remove whitespaces\n",
    "    text = text.apply(lambda x: \" \".join(x.strip() for x in x.split()))\n",
    "    \n",
    "    text = text.replace('\\n', ' ')\n",
    "    \n",
    "    # Remove special characters\n",
    "    text = text.apply(lambda x: \"\".join([\" \" if ord(i) < 32 or ord(i) > 126 else i for i in x]))\n",
    "    \n",
    "    # Remove punctuation\n",
    "    text = text.str.replace('[^\\w\\s]', '')\n",
    "    \n",
    "    # Remove numbers\n",
    "    text = text.str.replace('\\d+', '')\n",
    "    \n",
    "    # Remove Stopwords\n",
    "    text = text.apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
    "    \n",
    "    # Convert to string\n",
    "    text = text.astype(str)\n",
    "        \n",
    "    return text\n",
    "\n",
    "#function to combine title with description, so title will become a keyword as well.\n",
    "def combine_title_and_description(title, desc):\n",
    "    combine = title + desc\n",
    "    combine = remove_noise(combine)\n",
    "    return combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KimYiuLui\\Anaconda3\\envs\\minor\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "#create new column and fill the column with cleaned description\n",
    "data[\"cleaned_desc\"] = combine_title_and_description(data[\"Title\"], data[\"Description\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KimYiuLui\\Anaconda3\\envs\\minor\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# tokenize and further reduce common words\n",
    "token_desc = []\n",
    "for index, row in data.iterrows():\n",
    "    token_desc.append(word_tokenize(row[\"cleaned_desc\"]))\n",
    "    \n",
    "filter_token = []\n",
    "for arr in token_desc:\n",
    "    temp = []\n",
    "    for i in arr:\n",
    "        if not i in stopwords:\n",
    "             temp.append(i)\n",
    "    filter_token.append(temp)  \n",
    "    \n",
    "data['token_desc'] = filter_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KimYiuLui\\Anaconda3\\envs\\minor\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "#turn the array of token in 1 string\n",
    "token2string = []\n",
    "columns = ['token_desc'] \n",
    "for index, row in data.iterrows():\n",
    "    words = ''\n",
    "    for col in columns:\n",
    "        words += ' '.join(row[col]) + ' '\n",
    "    token2string.append(words)\n",
    "    \n",
    "data['bag_of_word'] = token2string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create cosine similarity matrix\n",
    "count = CountVectorizer()\n",
    "count_matrix = count.fit_transform(data['bag_of_word'])\n",
    "cosine_sim = cosine_similarity(count_matrix, count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = pd.Series(df['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recommend function\n",
    "def recommend(title, cosine_sim = cosine_sim):\n",
    "    recommend_books = []\n",
    "    idx = indices[indices == title].index[0]\n",
    "    score_series = pd.Series(cosine_sim[idx]).sort_values(ascending = False)\n",
    "    top_10_indices = list(score_series.iloc[1:11].index)\n",
    "    print(score_series.iloc[1:11])\n",
    "    for i in top_10_indices:\n",
    "        # we use df here because the index of df should be the samen as data\n",
    "        # also easier to obtain other information about of the similair books\n",
    "        recommend_books.append(list(df['title'])[i])\n",
    "        \n",
    "    return recommend_books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16266    0.244949\n",
      "1426     0.238366\n",
      "15613    0.234888\n",
      "42225    0.223607\n",
      "43110    0.223607\n",
      "1931     0.221781\n",
      "23178    0.221404\n",
      "20133    0.213201\n",
      "22362    0.210819\n",
      "39154    0.200000\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The New Urban Sociology',\n",
       " 'Critical Thinking Through Art Unit I',\n",
       " 'Urban Education : A Reference Handbook',\n",
       " \"84K : 'An eerily plausible dystopian masterpiece' Emily St John Mandel\",\n",
       " \"84K : 'An eerily plausible dystopian masterpiece' Emily St John Mandel\",\n",
       " '1776: A New Look at Revolutionary Williamsburg',\n",
       " 'Shepard Fairey, Inc. : Artist, Professional, Vandal',\n",
       " 'The Spellweaver Base Class Deluxe',\n",
       " 'Donald Judd',\n",
       " '2020 Watercolor Design Diary']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend('1984')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gaining Financial Empowerment : Four Simple Steps to Financial Freedom',\n",
       " 'Financial Reset : How Your Mindset about Money Affects Your Financial Well-Being',\n",
       " 'Understanding Consumer Financial Behavior : Money Management in an Age of Financial Illiteracy',\n",
       " 'Financial Illiteracy in America : Its Causes, Impact & Solutions',\n",
       " '100 of the Best Hockey Players of All Time',\n",
       " 'Brexit and Financial Regulation',\n",
       " 'Bitcoin Trading and Investing : Understanding Bitcoin Trading, Technical Analysis & 7 Trading Tips',\n",
       " \"We're in the Wrong Book!\",\n",
       " '2nd Revised edition of \\\\\"Technical Analysis of the Financial Markets: A Comprehensive Guide to Trading Methods and Applications\\\\\" : A Comprehensive Guide to Trading Methods and Applications',\n",
       " 'Financial Analysis, Planning And Forecasting: Theory And Application (2nd Edition)']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend('Basic Python in Finance : How to Implement Financial Trading Strategies and Analysis using Python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Learning C# 7 By Developing Games with Unity 2017 - Third Edition',\n",
       " 'Building an RPG with Unity 2018 - : Leverage the power of Unity 2018 to build elements of an RPG',\n",
       " 'Gamification with Unity 5.x',\n",
       " '2D to VR with Unity5 and Google Cardboard',\n",
       " '2D to VR with Unity5 and Google Cardboard',\n",
       " 'The Perfect Blend : A Practical Guide to Designing Student-Centered Learning Experiences',\n",
       " '150 Ways to Fund a Reality Show : Show me the Money',\n",
       " 'Machine Learning : A Comprehensive, Step-by-Step Guide to Learning and Understanding Machine Learning Concepts, Technology and Principles for Beginners',\n",
       " '12 Habits of Successful Trainers',\n",
       " '10 Must Reads : Learning, Engaging, Enriching']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend('Unity 5: Learning C# by Developing Games')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Adobe Photoshop CC Advanced and Basics of Photo Editing Techniques',\n",
       " '100% Photoshop : Create stunning illustrations without using any photographs',\n",
       " 'Photoshop : The beginners guide to Photoshop, Editing Photos, Photo Editing Tips, and How to Improve your Photography with Photoshop!',\n",
       " 'Photoshop Astronomy : Includes Full Res Tutorial Images on DVD',\n",
       " '3D Photoshop for Creative Professionals : Interactive Guide for Creating 3D Art',\n",
       " '45 Techniques Every Counselor Should Know',\n",
       " '100 Ways to Take Better Nature & Wildlife Photographs',\n",
       " \"2015 Photographer's Market\",\n",
       " '3D Game Textures : Create Professional Game Art Using Photoshop',\n",
       " 'So, You want to be a professional surfer. : A beginners guide']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend('Adobe Photoshop CC for Photographers 2018')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
